{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15afe59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   transaction_id               4543 non-null   float64       \n",
      " 1   fecha_registro               4643 non-null   datetime64[ns]\n",
      " 2   nombre_cliente_raw           4513 non-null   float64       \n",
      " 3   monto                        4539 non-null   float64       \n",
      " 4   categoria_producto_tipo      4639 non-null   object        \n",
      " 5   score                        4928 non-null   float64       \n",
      " 6   comentarios                  4651 non-null   object        \n",
      " 7   fraude                       4824 non-null   float64       \n",
      " 8   transaction_id_nan           5000 non-null   int64         \n",
      " 9   fecha_registro_nan           5000 non-null   int64         \n",
      " 10  nombre_cliente_raw_nan       5000 non-null   int64         \n",
      " 11  monto_nan                    5000 non-null   int64         \n",
      " 12  categoria_producto_tipo_nan  5000 non-null   int64         \n",
      " 13  score_nan                    5000 non-null   int64         \n",
      " 14  comentarios_nan              5000 non-null   int64         \n",
      " 15  fraude_nan                   5000 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(8), object(2)\n",
      "memory usage: 625.1+ KB\n",
      "\n",
      "Primeras filas del dataset:\n",
      "    transaction_id      fecha_registro  nombre_cliente_raw   monto  \\\n",
      "0              1.0 2020-01-01 00:00:00                 0.0  380.79   \n",
      "1              2.0 2020-01-01 01:00:00                 1.0  951.21   \n",
      "2              3.0 2020-01-01 02:00:00                 2.0  734.67   \n",
      "3              4.0 2020-01-01 03:00:00                 3.0  602.67   \n",
      "4              5.0 2020-01-01 04:00:00                 4.0  164.46   \n",
      "5              6.0 2020-01-01 05:00:00                 5.0  164.43   \n",
      "6              7.0 2020-01-01 06:00:00                 6.0   67.50   \n",
      "7              NaN 2020-01-01 07:00:00                 7.0  867.51   \n",
      "8              9.0 2020-01-01 08:00:00                 8.0  605.10   \n",
      "9             10.0 2020-01-01 09:00:00                 9.0  710.99   \n",
      "10            11.0 2020-01-01 10:00:00                10.0   30.38   \n",
      "11            12.0                 NaT                11.0  970.21   \n",
      "12            13.0 2020-01-01 12:00:00                12.0  834.12   \n",
      "13            14.0 2020-01-01 13:00:00                13.0  220.22   \n",
      "14             NaN 2020-01-01 14:00:00                14.0  190.01   \n",
      "\n",
      "   categoria_producto_tipo  score          comentarios  fraude  \\\n",
      "0                    Hogar    5.0  q a h f t r x c k a     0.0   \n",
      "1                    Hogar    2.0  f n a f q o f p v a     0.0   \n",
      "2                 Juguetes    2.0  u s i e y i c c w p     0.0   \n",
      "3                    Hogar    4.0  u s n z j o v q w p     1.0   \n",
      "4                   Libros    3.0  s b f h c g c h q j     0.0   \n",
      "5                     <NA>    1.0  j f g y q p e s e j     0.0   \n",
      "6                   Libros    3.0  z q o r v u f a i g     NaN   \n",
      "7                    Hogar    2.0  f y w i r k x l g g     0.0   \n",
      "8                   Libros    5.0  o g p x k f z n c b     0.0   \n",
      "9                    Hogar    1.0  c q u k b j z n z w     0.0   \n",
      "10                   Hogar    1.0  a s r n g q c l l y     0.0   \n",
      "11                    Ropa    5.0  w g n e x w h q p d     0.0   \n",
      "12                  Libros    1.0  t o u n a i a y w v     0.0   \n",
      "13                  Libros    5.0  h b w y c m b t t d     0.0   \n",
      "14                  Libros    1.0  m o g w l f o s f i     0.0   \n",
      "\n",
      "    transaction_id_nan  fecha_registro_nan  nombre_cliente_raw_nan  monto_nan  \\\n",
      "0                    0                   0                       0          0   \n",
      "1                    0                   0                       0          0   \n",
      "2                    0                   0                       0          0   \n",
      "3                    0                   0                       0          0   \n",
      "4                    0                   0                       0          0   \n",
      "5                    0                   0                       0          0   \n",
      "6                    0                   0                       0          0   \n",
      "7                    1                   0                       0          0   \n",
      "8                    0                   0                       0          0   \n",
      "9                    0                   0                       0          0   \n",
      "10                   0                   0                       0          0   \n",
      "11                   0                   1                       0          0   \n",
      "12                   0                   0                       0          0   \n",
      "13                   0                   0                       0          0   \n",
      "14                   1                   0                       0          0   \n",
      "\n",
      "    categoria_producto_tipo_nan  score_nan  comentarios_nan  fraude_nan  \n",
      "0                             0          0                0           0  \n",
      "1                             0          0                0           0  \n",
      "2                             0          0                0           0  \n",
      "3                             0          0                0           0  \n",
      "4                             0          0                0           0  \n",
      "5                             1          0                0           0  \n",
      "6                             0          0                0           1  \n",
      "7                             0          0                0           0  \n",
      "8                             0          0                0           0  \n",
      "9                             0          0                0           0  \n",
      "10                            0          0                0           0  \n",
      "11                            0          0                0           0  \n",
      "12                            0          0                0           0  \n",
      "13                            0          0                0           0  \n",
      "14                            0          0                0           0  \n",
      "\n",
      "Calidad de datos:\n",
      "transaction_id                 457\n",
      "fecha_registro                 357\n",
      "nombre_cliente_raw             487\n",
      "monto                          461\n",
      "categoria_producto_tipo        361\n",
      "score                           72\n",
      "comentarios                    349\n",
      "fraude                         176\n",
      "transaction_id_nan               0\n",
      "fecha_registro_nan               0\n",
      "nombre_cliente_raw_nan           0\n",
      "monto_nan                        0\n",
      "categoria_producto_tipo_nan      0\n",
      "score_nan                        0\n",
      "comentarios_nan                  0\n",
      "fraude_nan                       0\n",
      "dtype: int64\n",
      "\n",
      "Dimension del dataset (filas, columnas):\n",
      "(5000, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# -------------------------------\n",
    "# Loaders\n",
    "# -------------------------------\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Clase base para cargar datos desde un archivo.\n",
    "    \n",
    "    Parametros:\n",
    "    -----------\n",
    "    filepath : str o Path\n",
    "        Ruta al archivo que se desea cargar.\n",
    "    \"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = Path(filepath)\n",
    "\n",
    "    def read_file(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Metodo base que debe ser sobrescrito por cada loader especifico.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Este metodo debe ser implementado por subclases\")\n",
    "\n",
    "\n",
    "class CSVLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    Carga archivos CSV.\n",
    "    \"\"\"\n",
    "    def read_file(self, **kwargs):\n",
    "        return pd.read_csv(self.filepath, **kwargs)\n",
    "\n",
    "\n",
    "class ExcelLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    Carga archivos Excel (.xls y .xlsx).\n",
    "    \"\"\"\n",
    "    def read_file(self, **kwargs):\n",
    "        return pd.read_excel(self.filepath, **kwargs)\n",
    "\n",
    "\n",
    "class JSONLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    Carga archivos JSON.\n",
    "    \"\"\"\n",
    "    def read_file(self, **kwargs):\n",
    "        return pd.read_json(self.filepath, **kwargs)\n",
    "\n",
    "\n",
    "# Asociacion entre extension y Loader\n",
    "LOADER_FACTORY = {\n",
    "    \".csv\": CSVLoader,\n",
    "    \".xlsx\": ExcelLoader,\n",
    "    \".xls\": ExcelLoader,\n",
    "    \".json\": JSONLoader,\n",
    "    \".txt\": CSVLoader\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Clase para el Data PreProcessor\n",
    "# -------------------------------\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Clase para preprocesamiento de DataFrames.\n",
    "    \n",
    "    Parametros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a procesar.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def clean_columns(self):\n",
    "        \"\"\"\n",
    "        Normaliza los nombres de los columnas:\n",
    "        - Convierte a minusculas\n",
    "        - Reemplaza espacios por guoines bajos\n",
    "        - Elimina caracteres especiales\n",
    "        - Renombra columnas especificas a nombres estandar\n",
    "        \"\"\"\n",
    "        def limpiar_caracteres(col):\n",
    "            col = str(col)\n",
    "            col = unicodedata.normalize(\"NFKD\", col)\n",
    "            col = col.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "            col = col.lower()\n",
    "            col = re.sub(r\"\\s+\", \"_\", col)\n",
    "            col = col.replace(\"@\", \"a\").replace(\"/\", \"_\")\n",
    "            col = re.sub(r\"[^a-z0-9_]\", \"\", col)\n",
    "            col = re.sub(r\"_+\", \"_\", col).strip(\"_\")\n",
    "            return col\n",
    "\n",
    "        self.df.columns = [limpiar_caracteres(c) for c in self.df.columns]\n",
    "\n",
    "        # Renombrar columnas especificas si existen\n",
    "        rename_map = {\n",
    "            \"score_15\": \"score\",\n",
    "            \"es_fraude\": \"fraude\",\n",
    "            \"notes_comments\": \"comentarios\"\n",
    "        }\n",
    "        self.df.rename(columns={k: v for k, v in rename_map.items() if k in self.df.columns}, inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def vacios_a_nulos(self):\n",
    "        \"\"\"\n",
    "        Convierte valores vacios, espacios en blanco o string 'nan' a valores NaN.\n",
    "        \"\"\"\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype == \"object\":\n",
    "                # Convertimos a string y reemplazamos espacios vacios por NaN\n",
    "                self.df[col] = self.df[col].astype(\"string\").replace(r\"^\\s*$\", pd.NA, regex=True)\n",
    "                # Convertimos string \"nan\" a NaN\n",
    "                self.df[col] = self.df[col].replace(\"nan\", pd.NA)\n",
    "        return self.df\n",
    "\n",
    "    def limpieza_monto(self, col_name=\"monto\"):\n",
    "        \"\"\"\n",
    "        Limpieza de columnas numericas que representan montos:\n",
    "        - Elimina simbolos de dolar y comas\n",
    "        - Convierte a tipo numerico\n",
    "        \"\"\"\n",
    "        if col_name in self.df.columns:\n",
    "            self.df[col_name] = (\n",
    "                self.df[col_name].astype(str)\n",
    "                .str.replace(\"$\", \"\", regex=False)\n",
    "                .str.replace(\",\", \"\", regex=False)\n",
    "                .str.strip()\n",
    "            )\n",
    "            self.df[col_name] = pd.to_numeric(self.df[col_name], errors=\"coerce\")\n",
    "        return self.df\n",
    "\n",
    "    def limpieza_num_cliente(self, col_name=\"nombre_cliente_raw\"):\n",
    "        \"\"\"\n",
    "        Extrae numeros de columnas de clientes y los convierte a numerico.\n",
    "        \"\"\"\n",
    "        if col_name in self.df.columns:\n",
    "            self.df[col_name] = self.df[col_name].astype(str).str.extract(r\"(\\d+)\")\n",
    "            self.df[col_name] = pd.to_numeric(self.df[col_name], errors=\"coerce\")\n",
    "        return self.df\n",
    "\n",
    "    def limpieza_score(self, col_name=\"score\"):\n",
    "        \"\"\"\n",
    "        Convierte columnas de score de texto a numerico (uno=1, dos=2, etc.).\n",
    "        \"\"\"\n",
    "        if col_name in self.df.columns:\n",
    "            mapping = {\"uno\": 1, \"dos\": 2, \"tres\": 3, \"cuatro\": 4, \"cinco\": 5}\n",
    "            self.df[col_name] = self.df[col_name].astype(str).str.lower().str.strip()\n",
    "            self.df[col_name] = self.df[col_name].replace(mapping)\n",
    "            self.df[col_name] = pd.to_numeric(self.df[col_name], errors=\"coerce\")\n",
    "        return self.df\n",
    "\n",
    "    def eliminar_acentos(self):\n",
    "        \"\"\"\n",
    "        Elimina acentos de todas las columnas de tipo string.\n",
    "        \"\"\"\n",
    "        for col in self.df.select_dtypes(include=[\"string\"]).columns:\n",
    "            self.df[col] = self.df[col].apply(\n",
    "                lambda x: unicodedata.normalize(\"NFKD\", x).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "                if pd.notna(x) else x\n",
    "            )\n",
    "        return self.df\n",
    "\n",
    "    def limpieza_fecha_registro(self, col_name=\"fecha_registro\"):\n",
    "        \"\"\"\n",
    "        Convierte columnas de fecha a datetime.\n",
    "        \"\"\"\n",
    "        if col_name in self.df.columns:\n",
    "            self.df[col_name] = pd.to_datetime(self.df[col_name], errors=\"coerce\")\n",
    "        return self.df\n",
    "\n",
    "    def ban_columnas_nulas(self):\n",
    "        \"\"\"\n",
    "        Crea columnas bandera indicando la presencia de valores nulos.\n",
    "        \"\"\"\n",
    "        for col in self.df.columns:\n",
    "            self.df[f\"{col}_nan\"] = self.df[col].isna().astype(int)\n",
    "        return self.df\n",
    "\n",
    "    def calidad_df(self):\n",
    "        \"\"\"\n",
    "        Retorna informacion basica de calidad del DataFrame:\n",
    "        - info() del DataFrame\n",
    "        - resumen de valores nulos\n",
    "        \"\"\"\n",
    "        info = self.df.info()\n",
    "        null_summary = self.df.isna().sum()\n",
    "        return {\"info\": info, \"null_summary\": null_summary}\n",
    "\n",
    "# -------------------------------\n",
    "# Funcion principal\n",
    "# -------------------------------\n",
    "\n",
    "def carga_procesa(filepath, **kwargs):\n",
    "    \"\"\"\n",
    "    Carga un archivo y aplica procesamiento estandar:\n",
    "    - Limpieza de columnas\n",
    "    - Conversion de vacios a NaN\n",
    "    - Limpieza de montos, scores y fechas\n",
    "    - Eliminacion de acentos\n",
    "    - Creacion de columnas bandera de nulos\n",
    "\n",
    "    Parametros:\n",
    "    -----------\n",
    "    filepath : str o Path\n",
    "        Ruta al archivo a procesar.\n",
    "    **kwargs : dict\n",
    "        Argumentos adicionales para el loader correspondiente (sep, encoding, etc.)\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame procesado.\n",
    "    calidad : dict\n",
    "        Informacion de calidad del DataFrame.\n",
    "    \"\"\"\n",
    "    filepath = Path(filepath)\n",
    "    ext = filepath.suffix.lower()\n",
    "    if ext not in LOADER_FACTORY:\n",
    "        raise ValueError(f\"Formato no soportado: {ext}\")\n",
    "\n",
    "    # Carga del archivo usando el loader adecuado\n",
    "    loader = LOADER_FACTORY[ext](filepath)\n",
    "    df = loader.read_file(**kwargs)\n",
    "\n",
    "    # Procesamiento de datos\n",
    "    processor = DataPreprocessor(df)\n",
    "    processor.clean_columns()\n",
    "    processor.vacios_a_nulos()\n",
    "    processor.limpieza_monto()\n",
    "    processor.limpieza_num_cliente()\n",
    "    processor.limpieza_score()\n",
    "    processor.limpieza_fecha_registro()\n",
    "    processor.eliminar_acentos()\n",
    "    processor.ban_columnas_nulas()\n",
    "\n",
    "    return processor.df, processor.calidad_df()\n",
    "\n",
    "# -------------------------------\n",
    "# Informacion global del DF\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    ruta_archivo = input(\"Ingrese la ruta del archivo: \").strip()\n",
    "    try:\n",
    "        df, quality = carga_procesa(ruta_archivo, sep=\",\", encoding=\"utf-8\")\n",
    "        print(\"\\nPrimeras filas del dataset:\")\n",
    "        print(df.head(15))\n",
    "        print(\"\\nCalidad de datos:\")\n",
    "        print(quality[\"null_summary\"])\n",
    "        print(\"\\nDimension del dataset (filas, columnas):\")\n",
    "        print(df.shape)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
