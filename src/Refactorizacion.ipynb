{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15afe59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Tras la evaluacion del contenido del archivo, se concluye que:\n",
      "\n",
      "EL SET DE DATOS ES APTO PARA MODELOS DE ML>\n",
      "\n",
      "Calidad de datos (valores nulos por columna):\n",
      "transaction_id             457\n",
      "fecha_registro             357\n",
      "nombre_cliente_raw         487\n",
      "monto                      461\n",
      "categoria_producto_tipo    361\n",
      "score                       72\n",
      "comentarios                349\n",
      "fraude                     176\n",
      "dtype: int64\n",
      "\n",
      "Vista del DataFrame final (primeras 5 filas):\n",
      "|   transaction_id | fecha_registro      |   nombre_cliente_raw |   monto | categoria_producto_tipo   |   score | comentarios         |   fraude |   transaction_id_nan |   fecha_registro_nan |   nombre_cliente_raw_nan |   monto_nan |   categoria_producto_tipo_nan |   score_nan |   comentarios_nan |   fraude_nan |\n",
      "|-----------------:|:--------------------|---------------------:|--------:|:--------------------------|--------:|:--------------------|---------:|---------------------:|---------------------:|-------------------------:|------------:|------------------------------:|------------:|------------------:|-------------:|\n",
      "|                1 | 2020-01-01 00:00:00 |                    0 |  380.79 | Hogar                     |       5 | q a h f t r x c k a |        0 |                    0 |                    0 |                        0 |           0 |                             0 |           0 |                 0 |            0 |\n",
      "|                2 | 2020-01-01 01:00:00 |                    1 |  951.21 | Hogar                     |       2 | f n a f q o f p v a |        0 |                    0 |                    0 |                        0 |           0 |                             0 |           0 |                 0 |            0 |\n",
      "|                3 | 2020-01-01 02:00:00 |                    2 |  734.67 | Juguetes                  |       2 | u s i e y i c c w p |        0 |                    0 |                    0 |                        0 |           0 |                             0 |           0 |                 0 |            0 |\n",
      "|                4 | 2020-01-01 03:00:00 |                    3 |  602.67 | Hogar                     |       4 | u s n z j o v q w p |        1 |                    0 |                    0 |                        0 |           0 |                             0 |           0 |                 0 |            0 |\n",
      "|                5 | 2020-01-01 04:00:00 |                    4 |  164.46 | Libros                    |       3 | s b f h c g c h q j |        0 |                    0 |                    0 |                        0 |           0 |                             0 |           0 |                 0 |            0 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "import re\n",
    "import tabulate\n",
    "\n",
    "# -------------------------------\n",
    "# Excepción de calidad de datos\n",
    "# -------------------------------\n",
    "\n",
    "class DataQualityException(Exception):\n",
    "    \"\"\"Excepción para problemas críticos de calidad de datos.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Loaders\n",
    "# -------------------------------\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Clase base para cargar datos desde un archivo.\n",
    "    \n",
    "    Parametros:\n",
    "    -----------\n",
    "    filepath : str o Path\n",
    "        Ruta al archivo que se desea cargar.\n",
    "    \"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = Path(filepath)\n",
    "\n",
    "    def read_file(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Metodo base que debe ser sobresrito por cada loader especifico.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Este metodo debe ser implementado por subclases\")\n",
    "\n",
    "\n",
    "class CSVLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    Carga archivos CSV.\n",
    "    \"\"\"\n",
    "    def read_file(self, **kwargs):\n",
    "        return pd.read_csv(self.filepath, **kwargs)\n",
    "\n",
    "\n",
    "class ExcelLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    Carga archivos Excel (.xls y .xlsx).\n",
    "    \"\"\"\n",
    "    def read_file(self, **kwargs):\n",
    "        return pd.read_excel(self.filepath, **kwargs)\n",
    "\n",
    "\n",
    "class JSONLoader(DataLoader):\n",
    "    \"\"\"\n",
    "    Carga archivos JSON.\n",
    "    \"\"\"\n",
    "    def read_file(self, **kwargs):\n",
    "        return pd.read_json(self.filepath, **kwargs)\n",
    "\n",
    "\n",
    "# Asociacion entre extension y Loader\n",
    "LOADER_FACTORY = {\n",
    "    \".csv\": CSVLoader,\n",
    "    \".xlsx\": ExcelLoader,\n",
    "    \".xls\": ExcelLoader,\n",
    "    \".json\": JSONLoader,\n",
    "    \".txt\": CSVLoader\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Clase para el Data PreProcessor\n",
    "# -------------------------------\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Clase para preprocesamiento de DataFrames.\n",
    "    \n",
    "    Parametros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame a procesar.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def clean_columns(self):\n",
    "        \"\"\"\n",
    "        Normaliza los nombres de los columnas:\n",
    "        - Convierte a minusculas\n",
    "        - Reemplaza espacios por guiones bajos\n",
    "        - Elimina caracteres especiales\n",
    "        - Renombra columnas especificas a nombres estandar\n",
    "        \"\"\"\n",
    "        def limpiar_caracteres(col):\n",
    "            col = str(col)\n",
    "            col = unicodedata.normalize(\"NFKD\", col)\n",
    "            col = col.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "            col = col.lower()\n",
    "            col = re.sub(r\"\\s+\", \"_\", col)\n",
    "            col = col.replace(\"@\", \"a\").replace(\"/\", \"_\")\n",
    "            col = re.sub(r\"[^a-z0-9_]\", \"\", col)\n",
    "            col = re.sub(r\"_+\", \"_\", col).strip(\"_\")\n",
    "            return col\n",
    "\n",
    "        self.df.columns = [limpiar_caracteres(c) for c in self.df.columns]\n",
    "\n",
    "        # Renombrar columnas especificas si existen\n",
    "        rename_map = {\n",
    "            \"score_15\": \"score\",\n",
    "            \"es_fraude\": \"fraude\",\n",
    "            \"notes_comments\": \"comentarios\"\n",
    "        }\n",
    "        self.df.rename(\n",
    "            columns={k: v for k, v in rename_map.items() if k in self.df.columns},\n",
    "            inplace=True\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    def vacios_a_nulos(self):\n",
    "        \"\"\"\n",
    "        Convierte valores vacios, espacios en blanco o string 'nan' a valores NaN.\n",
    "        \"\"\"\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype == \"object\":\n",
    "                # Convertimos a string y reemplazamos espacios vacios por NaN\n",
    "                self.df[col] = self.df[col].astype(\"string\").replace(\n",
    "                    r\"^\\s*$\", pd.NA, regex=True\n",
    "                )\n",
    "                # Convertimos string \"nan\" a NaN\n",
    "                self.df[col] = self.df[col].replace(\"nan\", pd.NA)\n",
    "        return self.df\n",
    "\n",
    "    def limpieza_monto(self, col_name=\"monto\"):\n",
    "        \"\"\"\n",
    "        Limpieza de columnas numericas que representan montos:\n",
    "        - Elimina simbolos de dolar y comas\n",
    "        - Convierte a tipo numerico\n",
    "        \"\"\"\n",
    "        if col_name in self.df.columns:\n",
    "            self.df[col_name] = (\n",
    "                self.df[col_name].astype(str)\n",
    "                .str.replace(\"$\", \"\", regex=False)\n",
    "                .str.replace(\",\", \"\", regex=False)\n",
    "                .str.strip()\n",
    "            )\n",
    "            self.df[col_name] = pd.to_numeric(self.df[col_name], errors=\"coerce\")\n",
    "        return self.df\n",
    "\n",
    "    def limpieza_num_cliente(self, col_name=\"nombre_cliente_raw\"):\n",
    "        \"\"\"\n",
    "        Extrae numeros de columnas de clientes y los convierte a numerico.\n",
    "        \"\"\"\n",
    "        if col_name in self.df.columns:\n",
    "            self.df[col_name] = self.df[col_name].astype(str).str.extract(r\"(\\d+)\")\n",
    "            self.df[col_name] = pd.to_numeric(self.df[col_name], errors=\"coerce\")\n",
    "        return self.df\n",
    "\n",
    "    def limpieza_score(self, col_name=\"score\"):\n",
    "        \"\"\"\n",
    "        Convierte columnas de score de texto a numerico (uno=1, dos=2, etc.).\n",
    "        \"\"\"\n",
    "        if col_name in self.df.columns:\n",
    "            mapping = {\"uno\": 1, \"dos\": 2, \"tres\": 3, \"cuatro\": 4, \"cinco\": 5}\n",
    "            self.df[col_name] = self.df[col_name].astype(str).str.lower().str.strip()\n",
    "            self.df[col_name] = self.df[col_name].replace(mapping)\n",
    "            self.df[col_name] = pd.to_numeric(self.df[col_name], errors=\"coerce\")\n",
    "        return self.df\n",
    "\n",
    "    def eliminar_acentos(self):\n",
    "        \"\"\"\n",
    "        Elimina acentos de todas las columnas de tipo string.\n",
    "        \"\"\"\n",
    "        for col in self.df.select_dtypes(include=[\"string\"]).columns:\n",
    "            self.df[col] = self.df[col].apply(\n",
    "                lambda x: unicodedata.normalize(\"NFKD\", x)\n",
    "                .encode(\"ascii\", \"ignore\")\n",
    "                .decode(\"utf-8\")\n",
    "                if pd.notna(x) else x\n",
    "            )\n",
    "        return self.df\n",
    "\n",
    "    def limpieza_fecha_registro(self, col_name=\"fecha_registro\"):\n",
    "        \"\"\"\n",
    "        Convierte columnas de fecha a datetime.\n",
    "        \"\"\"\n",
    "        if col_name in self.df.columns:\n",
    "            self.df[col_name] = pd.to_datetime(self.df[col_name], errors=\"coerce\")\n",
    "        return self.df\n",
    "\n",
    "    def ban_columnas_nulas(self):\n",
    "        \"\"\"\n",
    "        Crea columnas bandera indicando la presencia de valores nulos.\n",
    "        \"\"\"\n",
    "        for col in self.df.columns:\n",
    "            self.df[f\"{col}_nan\"] = self.df[col].isna().astype(int)\n",
    "        return self.df\n",
    "\n",
    "    def validar_nulos_criticos(\n",
    "        self,\n",
    "        target_col=\"fraude\",\n",
    "        monto_col=\"monto\",\n",
    "        umbral=0.10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Valida si columnas criticas superan un umbral de nulos.\n",
    "        \"\"\"\n",
    "        alertas = []\n",
    "\n",
    "        for col in [target_col, monto_col]:\n",
    "            if col in self.df.columns:\n",
    "                porcentaje_nulos = self.df[col].isna().mean()\n",
    "\n",
    "                if porcentaje_nulos > umbral:\n",
    "                    alertas.append(\n",
    "                        f\"- Columna '{col}' tiene {porcentaje_nulos:.2%} de nulos \"\n",
    "                        f\"(umbral permitido: {umbral:.0%})\"\n",
    "                    )\n",
    "\n",
    "        if alertas:\n",
    "            print(\n",
    "                \"\\nEL SET DE DATOS NO ES APTO PARA MODELOS DE ML\\n\"\n",
    "                \"Se recomienda DESCARTAR este set de datos.\"\n",
    "            )\n",
    "            print(\"\\n\".join(alertas))\n",
    "            raise DataQualityException(\"Falla en la calidad de datos\")\n",
    "\n",
    "        print(\"\\n<Tras la evaluacion del contenido del archivo, se concluye que:\")\n",
    "        print(\"\\nEL SET DE DATOS ES APTO PARA MODELOS DE ML>\")\n",
    "        return True\n",
    "\n",
    "    def calidad_df(self):\n",
    "        \"\"\"\n",
    "        Retorna informacion basica de calidad del DataFrame:\n",
    "        - resumen de valores nulos\n",
    "        - omite columnas que terminan en '_nan' (columnas bandera)\n",
    "        \"\"\"\n",
    "        # Filtrar columnas que no terminan en '_nan'\n",
    "        return self.df[[col for col in self.df.columns if not col.endswith(\"_nan\")]].isna().sum()\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Funcion principal\n",
    "# -------------------------------\n",
    "\n",
    "def carga_procesa(filepath, **kwargs):\n",
    "    \"\"\"\n",
    "    Carga un archivo y aplica procesamiento estandar:\n",
    "    - Limpieza de columnas\n",
    "    - Conversion de vacios a NaN\n",
    "    - Limpieza de montos, scores y fechas\n",
    "    - Eliminacion de acentos\n",
    "    - Creacion de columnas bandera de nulos\n",
    "    \"\"\"\n",
    "    filepath = Path(filepath)\n",
    "    ext = filepath.suffix.lower()\n",
    "    if ext not in LOADER_FACTORY:\n",
    "        raise ValueError(f\"Formato no soportado: {ext}\")\n",
    "\n",
    "    # Carga del archivo usando el loader adecuado\n",
    "    loader = LOADER_FACTORY[ext](filepath)\n",
    "    df = loader.read_file(**kwargs)\n",
    "\n",
    "    # Procesamiento de datos\n",
    "    processor = DataPreprocessor(df)\n",
    "    processor.clean_columns()\n",
    "    processor.vacios_a_nulos()\n",
    "    processor.limpieza_monto()\n",
    "    processor.limpieza_num_cliente()\n",
    "    processor.limpieza_score()\n",
    "    processor.limpieza_fecha_registro()\n",
    "    processor.eliminar_acentos()\n",
    "    processor.ban_columnas_nulas()\n",
    "\n",
    "    # Validacion critica de calidad de datos\n",
    "    processor.validar_nulos_criticos(\n",
    "        target_col=\"fraude\",\n",
    "        monto_col=\"monto\",\n",
    "        umbral=0.10\n",
    "    )\n",
    "\n",
    "    return processor.df, processor.calidad_df()\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Informacion global del DF\n",
    "# -------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ruta_archivo = input(\"Ingrese la ruta del archivo: \").strip()\n",
    "    try:\n",
    "        df, quality = carga_procesa(ruta_archivo, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "        # Imprimir calidad de datos\n",
    "        print(\"\\nCalidad de datos (valores nulos por columna):\")\n",
    "        print(quality)\n",
    "\n",
    "        # Muestra el DF tabulado\n",
    "        print(\"\\nVista del DataFrame final (primeras 5 filas):\")\n",
    "        print(df.head(5).to_markdown(index=False))\n",
    "\n",
    "    except DataQualityException:\n",
    "        print(\"\\nProceso detenido por falla critica de calidad de datos.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
